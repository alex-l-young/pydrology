{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Request USGS Streamflow Data.\n",
    "This notebook is an example of how to use pydrology to download and resample USGS streamflow data. The USGS provides gage data from streams and rivers across the united states, which can be accessed on their website (https://waterdata.usgs.gov/nwis). An example of the monitoring data can be found here (https://waterdata.usgs.gov/monitoring-location/04234000/#parameterCode=00065&period=P7D) for Fall Creek in Ithaca, NY. The data provided at each location is generally a gage measurement in feet and a discharge value that is derived from a rating curve. \n",
    "\n",
    "The general workflow for requesting USGS streamflow data is as follows:\n",
    "1. Request the gage/discharge data for a particular site using the function call below.\n",
    "2. Inspect the raw gage/discharge data for missing values and other issues.\n",
    "3. Handle any data cleaning and then the data is ready for use!\n",
    "4. (Optional) Downsample or upsample the data using the provided functions.\n",
    "5. Save the Data Frame."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Library imports.\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from datetime import datetime\n",
    "from pathlib import Path\n",
    "\n",
    "# Local imports.\n",
    "from pydrology.usgs.usgs_request import request_usgs_data\n",
    "from pydrology import plotting\n",
    "from pydrology import time_series"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Parameters for the request.\n",
    "# ---------------------------\n",
    "\n",
    "# Gage IDs. Found on the USGS page for the specific monitoring location.\n",
    "gage_dir = Path(r'Path to directory')\n",
    "gage_ids_df = pd.read_csv(gage_dir / 'usgs_stations_ny.csv')\n",
    "gage_id_list = [i[:-1] for i in gage_ids_df['station_number']]\n",
    "print(gage_id_list)\n",
    "\n",
    "# Parameter to get data for. 'discharge' or 'height'.\n",
    "parameter = 'height'\n",
    "\n",
    "# Start date in format yyyy-mm-dd. \"2022-06-24\"\n",
    "start_date = \"1970-01-01\" \n",
    "\n",
    "# Local start time in format HH:MM:SS.mmm. \"11:17:05.203\"\n",
    "start_time = \"00:00:00.000\" \n",
    "\n",
    "# End date in format yyyy-mm-dd. \"2022-06-24\"\n",
    "end_date = \"2023-01-02\" \n",
    "\n",
    "# Local end time in format HH:MM:SS.mmm. \"11:17:05.203\"\n",
    "end_time = \"00:00:00.000\" \n",
    "\n",
    "# Number of hour offset from GMT (+ or -) in format +/-HH:MM. \"-04:00\"\n",
    "gmt_offset = \"-05:00\" \n",
    "\n",
    "# Data processing flags.\n",
    "# -------------------------\n",
    "\n",
    "# Plot the inspection of the stream data.\n",
    "plot_data_inspection = False\n",
    "\n",
    "# Convert missing data to NaN.\n",
    "missing_to_nan = True\n",
    "\n",
    "# Standardize datetimes to a consecutive series.\n",
    "standardize_dates = True\n",
    "\n",
    "# Interpolate NaN values.\n",
    "interpolate_nan = True\n",
    "\n",
    "# Resample data to a specific time interval (set interval below).\n",
    "resample_data = True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def save_usgs_dataframe(df, gage_id):\n",
    "    fname = f'{gage_id}_{list(df.datetime)[0]}-{list(df.datetime)[-1]}.csv'\n",
    "    df.to_csv(gage_dir / fname, index=False)\n",
    "    \n",
    "\n",
    "def request_full_timeframe(gage_id, parameter, start_date, start_time, end_date, end_time, gmt_offset):\n",
    "    \"\"\"\n",
    "    Requests the full time frame of data in chunks.\n",
    "    \"\"\"\n",
    "    cur_end_date = end_date\n",
    "    cur_end_time = end_time\n",
    "    \n",
    "    for"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Batch request.\n",
    "for gage_id in gage_id_list:\n",
    "    # Request the gage data as a DataFrame.\n",
    "    try:\n",
    "        gage_df = request_usgs_data(gage_id, parameter, start_date, start_time, end_date, end_time, gmt_offset)\n",
    "    except Exception as e:\n",
    "        print(e)\n",
    "        continue\n",
    "\n",
    "    # Print the head and tail.\n",
    "    print(gage_df)\n",
    "\n",
    "    # =============================\n",
    "    # Inspect the data\n",
    "\n",
    "    # Plotting column names and missing value.\n",
    "    data_column_name = parameter\n",
    "    time_column_name = 'datetime'\n",
    "    missing_value = 'M'\n",
    "\n",
    "    if plot_data_inspection is True:\n",
    "        # Plot the valid, missing, and non-valid data as a bar chart.\n",
    "        plotting.plot_missing_ratio(gage_df, data_column_name)\n",
    "\n",
    "        # Plot the data as a time series.\n",
    "        plotting.plot_data_timeseries(gage_df, data_column_name, time_column_name, missing_value=missing_value)\n",
    "\n",
    "    # ==============================\n",
    "    # Data Cleaning\n",
    "\n",
    "    dt = 15 # Time step in minutes.\n",
    "    data_column = parameter\n",
    "    time_column = 'datetime'\n",
    "\n",
    "    # ==============================\n",
    "    # Missing data to Nan.\n",
    "    if missing_to_nan is True:\n",
    "        missing_value = 'M'\n",
    "        gage_df.replace(missing_value, np.nan, inplace=True)\n",
    "\n",
    "    # ==============================\n",
    "    # Standardize datetime to insert missing time stamps.\n",
    "    if standardize_dates is True:\n",
    "        gage_df = time_series.standardize_datetime(gage_df, time_column, data_column, dt)\n",
    "\n",
    "    # ==============================\n",
    "    # Interpolate Nan Values.\n",
    "    if interpolate_nan is True:\n",
    "        gage_df = time_series.interpolate_time_series(gage_df, data_column, method='linear')\n",
    "\n",
    "    # ==============================\n",
    "    # Resample data.\n",
    "    if resample_data is True:\n",
    "        new_dt = 1440 # New time step in minutes. \n",
    "        data_column = parameter\n",
    "        time_column = 'datetime'\n",
    "        resample_gage_df = time_series.resample_data(gage_df, time_column, data_column, new_dt)\n",
    "        resample_gage_df.head()\n",
    "        save_usgs_dataframe(resample_gage_df, gage_id)\n",
    "    else:\n",
    "        save_usgs_dataframe(gage_df, gage_id)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "pydrology-env",
   "language": "python",
   "name": "pydrology-env"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
